{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuaMYp+89t12MaBL1Vh930",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tleyden/FruitPunch_AI_Bootcamp/blob/main/FruitPunch_Capstone_Project_YOLO_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pip installs"
      ],
      "metadata": {
        "id": "Y_6rPZmkpH_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install -y jq\n",
        "!pip install pycocotools\n",
        "!python -m pip install pyyaml==5.1\n",
        "!pip install wandb -qU\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lVa3C0lpLSA",
        "outputId": "c4444786-284a-45ef-9758-fd58f98aba2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libjq1 libonig4\n",
            "The following NEW packages will be installed:\n",
            "  jq libjq1 libonig4\n",
            "0 upgraded, 3 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 276 kB of archives.\n",
            "After this operation, 930 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libonig4 amd64 6.7.0-1 [119 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libjq1 amd64 1.5+dfsg-2 [111 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 jq amd64 1.5+dfsg-2 [45.6 kB]\n",
            "Fetched 276 kB in 0s (829 kB/s)\n",
            "Selecting previously unselected package libonig4:amd64.\n",
            "(Reading database ... 124016 files and directories currently installed.)\n",
            "Preparing to unpack .../libonig4_6.7.0-1_amd64.deb ...\n",
            "Unpacking libonig4:amd64 (6.7.0-1) ...\n",
            "Selecting previously unselected package libjq1:amd64.\n",
            "Preparing to unpack .../libjq1_1.5+dfsg-2_amd64.deb ...\n",
            "Unpacking libjq1:amd64 (1.5+dfsg-2) ...\n",
            "Selecting previously unselected package jq.\n",
            "Preparing to unpack .../jq_1.5+dfsg-2_amd64.deb ...\n",
            "Unpacking jq (1.5+dfsg-2) ...\n",
            "Setting up libonig4:amd64 (6.7.0-1) ...\n",
            "Setting up libjq1:amd64 (1.5+dfsg-2) ...\n",
            "Setting up jq (1.5+dfsg-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (2.0.6)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from pycocotools) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pycocotools) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[K     |████████████████████████████████| 274 kB 4.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp38-cp38-linux_x86_64.whl size=44089 sha256=dac58e85c1fbcaa81db6a06c4f60e36a677b099c8b7cfbae92aea60d16c30cc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/dd/2b/10ff8b0ac81b93946bb5fb9e6749bae2dac246506c8774e6cf\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dask 2022.2.1 requires pyyaml>=5.3.1, but you have pyyaml 5.1 which is incompatible.\u001b[0m\n",
            "Successfully installed pyyaml-5.1\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 4.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 173 kB 37.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 65.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 81.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 86.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 85.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 88.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 83.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 85.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 158 kB 88.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 82.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 84.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 82.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 78.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 84.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 86.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 84.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 74.6 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "51m3p5WRsjSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "\n",
        "from pycocotools.coco import COCO\n",
        "import skimage.io as io\n",
        "from pathlib import Path\n",
        "\n",
        "import sys, distutils.core\n",
        "from google.colab.patches import cv2_imshow\n",
        "import json\n",
        "import shutil\n",
        "import yaml"
      ],
      "metadata": {
        "id": "B_V4uM35si1c"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weights and biases setup"
      ],
      "metadata": {
        "id": "kdJ3uuWVO5sA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "w7xr4jTKO8Y5",
        "outputId": "188a9d06-4a51-4449-ab0c-f4a6bfd0be36"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount google drive"
      ],
      "metadata": {
        "id": "UPxqYyCGSD3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4crRMlDCSFeX",
        "outputId": "3628b924-e970-4dde-d1e1-6fb5d335d81b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download zips from google bucket"
      ],
      "metadata": {
        "id": "UyXcuhJHr02I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "if not os.path.exists(\"Labeled data-20211126T095740Z-001.zip\"):\n",
        "    !gsutil cp \"gs://fruitpunch-ai-tleyden/Labeled data-20211126T095740Z-001.zip\" .\n",
        "if not os.path.exists(\"Labeled data-20211126T095740Z-002.zip\"):\n",
        "    !gsutil cp \"gs://fruitpunch-ai-tleyden/Labeled data-20211126T095740Z-002.zip\" .\n"
      ],
      "metadata": {
        "id": "Zax75VsOr5Ug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68cc8b50-76f1-44d6-9939-5c9da532cdae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://fruitpunch-ai-tleyden/Labeled data-20211126T095740Z-001.zip...\n",
            "| [1 files][  2.0 GiB/  2.0 GiB]   79.9 MiB/s                                   \n",
            "Operation completed over 1 objects/2.0 GiB.                                      \n",
            "Copying gs://fruitpunch-ai-tleyden/Labeled data-20211126T095740Z-002.zip...\n",
            "/ [1 files][809.6 MiB/809.6 MiB]   83.7 MiB/s                                   \n",
            "Operation completed over 1 objects/809.6 MiB.                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"labeled_data\"):\n",
        "    !unzip -q \"Labeled data-20211126T095740Z-001.zip\"\n",
        "    !unzip -q \"Labeled data-20211126T095740Z-002.zip\""
      ],
      "metadata": {
        "id": "4QT3o_GrsTJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Re-arrange directories to match expected structure"
      ],
      "metadata": {
        "id": "pfZpqkXBvnDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"labeled_data\"):\n",
        "    os.makedirs(\"labeled_data\")\n",
        "    !mv \"Labeled data\" labeled_data\n",
        "if not os.path.exists(\"labeled_data/images/test\"):\n",
        "    !mkdir labeled_data/images/test \n",
        "    !mv labeled_data/images/*.PNG labeled_data/images/test "
      ],
      "metadata": {
        "id": "rJa_ntnutA2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47817f48-d5c9-4022-e342-ea184339acf8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already have labeled_data dir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set some global variables"
      ],
      "metadata": {
        "id": "1h5iqPpTv1_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/labeled_data/'\n",
        "\n",
        "\n",
        "use_single_batch = False\n",
        "if use_single_batch:\n",
        "    # Smaller subset of dataset for faster iteration\n",
        "    LABELS_PATH = DATA_PATH + 'annotations_single_batch/'\n",
        "    IMAGES_PATH = DATA_PATH + 'images_single_batch/'\n",
        "else:\n",
        "    LABELS_PATH = DATA_PATH + 'annotations/'\n",
        "    IMAGES_PATH = DATA_PATH + 'images/'\n",
        "\n",
        "# Get paths to IMAGE directories\n",
        "TRAIN_IMAGES_PATH = IMAGES_PATH + 'train/'\n",
        "TEST_IMAGES_PATH = IMAGES_PATH + 'test/'\n",
        "VAL_IMAGES_PATH = IMAGES_PATH + 'val/'\n",
        "\n",
        "TRAIN_LABELS = LABELS_PATH + 'instances_train.json'\n",
        "TEST_LABELS = LABELS_PATH + 'instances_test_dataset.json'\n",
        "VAL_LABELS = LABELS_PATH + 'instances_val.json'\n",
        "\n"
      ],
      "metadata": {
        "id": "YZKCCXxgvZFN"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create single batch annotations\n",
        "\n",
        "Create a smaller dataset that can be used for faster iteration"
      ],
      "metadata": {
        "id": "QFinEDQXWKn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_single_batch_annotations(num_instances_to_collect):\n",
        "    \"\"\"\n",
        "    Create a copy of annotations/instances_train.json, instances_test_dataset.json and instances_val.json\n",
        "    in the annotations_single_batch directory with a smaller subset of annotations.\n",
        "    \"\"\"\n",
        "    source_annotations = [\"instances_train.json\", \"instances_test_dataset.json\", \"instances_val.json\"]\n",
        "    for source_annotation in source_annotations:\n",
        "        subset_json = {}\n",
        "        with open(os.path.join(DATA_PATH, \"annotations\", source_annotation), \"r\") as f:\n",
        "            instances_json = json.loads(f.read())\n",
        "        subset_json[\"licenses\"] = instances_json[\"licenses\"]\n",
        "        subset_json[\"info\"] = instances_json[\"info\"]\n",
        "        subset_json[\"categories\"] = instances_json[\"categories\"]\n",
        "        subset_images = []\n",
        "        subset_annotations = []\n",
        "        collected_image_ids = []\n",
        "        \n",
        "        for annotation_json in instances_json[\"annotations\"]:\n",
        "            if len(subset_annotations) >= num_instances_to_collect:\n",
        "                # We have collected enough\n",
        "                break\n",
        "            subset_annotations.append(annotation_json)\n",
        "            collected_image_ids.append(annotation_json[\"image_id\"])\n",
        "            \n",
        "        for image_json in instances_json[\"images\"]:\n",
        "            if image_json[\"id\"] not in collected_image_ids:\n",
        "                continue\n",
        "            subset_images.append(image_json)\n",
        "\n",
        "            # Copy image to target image dir\n",
        "            if \"test\" in source_annotation:\n",
        "                target_img_dir = \"test\"\n",
        "            elif \"train\" in source_annotation:\n",
        "                target_img_dir = \"train\"\n",
        "            elif \"val\" in source_annotation:\n",
        "                target_img_dir = \"val\"\n",
        "\n",
        "            file_name = image_json[\"file_name\"]\n",
        "            source_img = os.path.join(DATA_PATH, \"images\", target_img_dir, file_name)\n",
        "            target_img = os.path.join(DATA_PATH, \"images_single_batch\", target_img_dir, file_name)\n",
        "            if not os.path.exists(target_img):\n",
        "                os.link(source_img, target_img)\n",
        "\n",
        "\n",
        "        print(f\"For {source_annotation} collected {len(subset_annotations)} instances\")\n",
        "        subset_json[\"images\"] = subset_images\n",
        "        subset_json[\"annotations\"] = subset_annotations\n",
        "\n",
        "        # Write json to target dir\n",
        "        source_annotation_full_path = os.path.join(DATA_PATH, \"annotations_single_batch\", source_annotation)\n",
        "        with open(source_annotation_full_path, \"w\") as f:\n",
        "            json.dump(subset_json, f)\n",
        "        print(f\"Wrote {source_annotation_full_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "44MZIXAAWRlu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if use_single_batch:\n",
        "    if not os.path.exists(os.path.join(DATA_PATH, \"annotations_single_batch\")):\n",
        "        os.makedirs(os.path.join(DATA_PATH, \"annotations_single_batch\"))\n",
        "    if not os.path.exists(os.path.join(DATA_PATH, \"images_single_batch\")):\n",
        "        os.makedirs(os.path.join(DATA_PATH, \"images_single_batch\"))\n",
        "        os.makedirs(os.path.join(DATA_PATH, \"images_single_batch\", \"train\"))\n",
        "        os.makedirs(os.path.join(DATA_PATH, \"images_single_batch\", \"test\"))\n",
        "        os.makedirs(os.path.join(DATA_PATH, \"images_single_batch\", \"val\"))\n",
        "\n",
        "create_single_batch_annotations(64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msxKl_wvIxcf",
        "outputId": "24176dfa-dbfe-413a-9f47-9df3d93fe91b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For instances_train.json collected 64 instances\n",
            "Wrote /content/labeled_data/annotations_single_batch/instances_train.json\n",
            "For instances_test_dataset.json collected 64 instances\n",
            "Wrote /content/labeled_data/annotations_single_batch/instances_test_dataset.json\n",
            "For instances_val.json collected 64 instances\n",
            "Wrote /content/labeled_data/annotations_single_batch/instances_val.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert annotations from coco -> yolo format"
      ],
      "metadata": {
        "id": "IRb7NnkpGzY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/JSON2YOLO.git  # clone repo\n",
        "%pip install -qr JSON2YOLO/requirements.txt # install dependencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1Psxob0G41J",
        "outputId": "83a12d43-1fd9-4dc6-c4c2-f95c39ff2289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'JSON2YOLO'...\n",
            "remote: Enumerating objects: 277, done.\u001b[K\n",
            "remote: Counting objects: 100% (113/113), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 277 (delta 102), reused 84 (delta 82), pack-reused 164\u001b[K\n",
            "Receiving objects: 100% (277/277), 74.65 KiB | 1.96 MiB/s, done.\n",
            "Resolving deltas: 100% (177/177), done.\n",
            "/content/JSON2YOLO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from general_json2yolo import convert_coco_json\n",
        "\n",
        "if use_single_batch:\n",
        "    convert_coco_json('/content/labeled_data/annotations_single_batch')\n",
        "else:\n",
        "    convert_coco_json('/content/labeled_data/annotations')"
      ],
      "metadata": {
        "id": "BJBH8kLjG9-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e5edccd-8981-457f-87ba-c34caf7976b3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Annotations /content/labeled_data/annotations/instances_test_dataset.json: 100%|██████████| 1900/1900 [00:00<00:00, 4920.98it/s]\n",
            "Annotations /content/labeled_data/annotations/instances_train.json: 100%|██████████| 13111/13111 [00:01<00:00, 7081.87it/s]\n",
            "Annotations /content/labeled_data/annotations/instances_val.json: 100%|██████████| 3278/3278 [00:00<00:00, 7147.11it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy images to yolo dir"
      ],
      "metadata": {
        "id": "Y1DWJ-BPJh78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if use_single_batch:\n",
        "    imgs_source_dir = os.path.join(\"labeled_data\", \"images_single_batch\")\n",
        "else:\n",
        "    imgs_source_dir = os.path.join(\"labeled_data\", \"images\")\n",
        "\n",
        "imgs_train = os.path.join(imgs_source_dir, \"train\")\n",
        "imgs_test = os.path.join(imgs_source_dir, \"test\")\n",
        "imgs_val = os.path.join(imgs_source_dir, \"val\")\n",
        "\n",
        "imgs_target_dir = os.path.join(\"new_dir\", \"labels\")\n",
        "imgs_target_train =  os.path.join(imgs_target_dir, \"train\")\n",
        "imgs_target_test =  os.path.join(imgs_target_dir, \"test_dataset\")\n",
        "imgs_target_val =  os.path.join(imgs_target_dir, \"val\")\n",
        "\n",
        "!cp {imgs_train}/*.PNG {imgs_target_train}/\n",
        "!cp {imgs_test}/*.PNG {imgs_target_test}/\n",
        "!cp {imgs_val}/*.PNG {imgs_target_val}/\n"
      ],
      "metadata": {
        "id": "CBBELtKZI97_"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create yolo data yaml file"
      ],
      "metadata": {
        "id": "LRmq8YRiMHJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_data_yaml = {\n",
        "    \"nc\": 1,\n",
        "    \"names\": [\"Human\"],\n",
        "    \"train\": [\"/content/new_dir/labels/train\"],\n",
        "    \"test\": [\"/content/new_dir/labels/test_dataset\"],\n",
        "    \"val\": [\"/content/new_dir/labels/val\"]\n",
        "}\n",
        "\n",
        "with open('data.yaml', 'w') as file:\n",
        "    yaml.dump(yolo_data_yaml, file)"
      ],
      "metadata": {
        "id": "I3JkAPXdMIwY"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qYHz9ks2Nujd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install yolo"
      ],
      "metadata": {
        "id": "UH5X22BfOWKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"yolov5\"):\n",
        "    !git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "    %pip install -qr yolov5/requirements.txt # install dependencies\n"
      ],
      "metadata": {
        "id": "tNVy0GuqOXsa"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train yolo"
      ],
      "metadata": {
        "id": "Ql91i27LOJ_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov5/train.py --img 640 --batch 64 --epochs 300 --data data.yaml --weights yolov5s.pt --cache\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x32hDrtOLXA",
        "outputId": "85e945a4-8371-40fb-d5f3-97427c743e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtleyden\u001b[0m (\u001b[33meyepi\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=data.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=300, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-34-g1ae9194 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20221215_194318-4pkylcqz\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mazure-sponge-194\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/eyepi/train\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/eyepi/train/runs/4pkylcqz\u001b[0m\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/new_dir/labels/train.cache... 13111 images, 0 backgrounds, 0 corrupt: 100% 13111/13111 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m11.0GB RAM required, 9.3/12.7GB available, not caching images ⚠️\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/new_dir/labels/val.cache... 3278 images, 0 backgrounds, 0 corrupt: 100% 3278/3278 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (2.8GB ram): 100% 3278/3278 [00:17<00:00, 184.07it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.73 anchors/target, 0.996 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to yolov5/runs/train/exp8/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1myolov5/runs/train/exp8\u001b[0m\n",
            "Starting training for 300 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      0/299      14.2G      0.101    0.01957          0        234        640: 100% 205/205 [05:37<00:00,  1.65s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  19% 5/26 [00:08<00:30,  1.44s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gso0LVZKOh4O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}