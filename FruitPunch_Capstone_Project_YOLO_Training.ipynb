{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMv9ASwBIceUO/ArtYrRebQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tleyden/FruitPunch_AI_Bootcamp/blob/main/FruitPunch_Capstone_Project_YOLO_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pip installs"
      ],
      "metadata": {
        "id": "Y_6rPZmkpH_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install -y jq\n",
        "!pip install pycocotools\n",
        "!python -m pip install pyyaml==5.1\n",
        "!pip install wandb -qU\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lVa3C0lpLSA",
        "outputId": "c4444786-284a-45ef-9758-fd58f98aba2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libjq1 libonig4\n",
            "The following NEW packages will be installed:\n",
            "  jq libjq1 libonig4\n",
            "0 upgraded, 3 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 276 kB of archives.\n",
            "After this operation, 930 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libonig4 amd64 6.7.0-1 [119 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libjq1 amd64 1.5+dfsg-2 [111 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 jq amd64 1.5+dfsg-2 [45.6 kB]\n",
            "Fetched 276 kB in 0s (829 kB/s)\n",
            "Selecting previously unselected package libonig4:amd64.\n",
            "(Reading database ... 124016 files and directories currently installed.)\n",
            "Preparing to unpack .../libonig4_6.7.0-1_amd64.deb ...\n",
            "Unpacking libonig4:amd64 (6.7.0-1) ...\n",
            "Selecting previously unselected package libjq1:amd64.\n",
            "Preparing to unpack .../libjq1_1.5+dfsg-2_amd64.deb ...\n",
            "Unpacking libjq1:amd64 (1.5+dfsg-2) ...\n",
            "Selecting previously unselected package jq.\n",
            "Preparing to unpack .../jq_1.5+dfsg-2_amd64.deb ...\n",
            "Unpacking jq (1.5+dfsg-2) ...\n",
            "Setting up libonig4:amd64 (6.7.0-1) ...\n",
            "Setting up libjq1:amd64 (1.5+dfsg-2) ...\n",
            "Setting up jq (1.5+dfsg-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (2.0.6)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from pycocotools) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pycocotools) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[K     |████████████████████████████████| 274 kB 4.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp38-cp38-linux_x86_64.whl size=44089 sha256=dac58e85c1fbcaa81db6a06c4f60e36a677b099c8b7cfbae92aea60d16c30cc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/dd/2b/10ff8b0ac81b93946bb5fb9e6749bae2dac246506c8774e6cf\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dask 2022.2.1 requires pyyaml>=5.3.1, but you have pyyaml 5.1 which is incompatible.\u001b[0m\n",
            "Successfully installed pyyaml-5.1\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 4.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 173 kB 37.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 65.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 81.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 86.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 85.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 88.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 83.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 85.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 158 kB 88.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 82.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 84.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 82.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 78.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 84.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 86.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 84.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 74.6 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "51m3p5WRsjSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "\n",
        "from pycocotools.coco import COCO\n",
        "import skimage.io as io\n",
        "from pathlib import Path\n",
        "\n",
        "import sys, distutils.core\n",
        "from google.colab.patches import cv2_imshow\n",
        "import json\n",
        "import shutil"
      ],
      "metadata": {
        "id": "B_V4uM35si1c"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount google drive"
      ],
      "metadata": {
        "id": "UPxqYyCGSD3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4crRMlDCSFeX",
        "outputId": "3628b924-e970-4dde-d1e1-6fb5d335d81b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download zips from google bucket"
      ],
      "metadata": {
        "id": "UyXcuhJHr02I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "if not os.path.exists(\"Labeled data-20211126T095740Z-001.zip\"):\n",
        "    !gsutil cp \"gs://fruitpunch-ai-tleyden/Labeled data-20211126T095740Z-001.zip\" .\n",
        "if not os.path.exists(\"Labeled data-20211126T095740Z-002.zip\"):\n",
        "    !gsutil cp \"gs://fruitpunch-ai-tleyden/Labeled data-20211126T095740Z-002.zip\" .\n"
      ],
      "metadata": {
        "id": "Zax75VsOr5Ug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68cc8b50-76f1-44d6-9939-5c9da532cdae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://fruitpunch-ai-tleyden/Labeled data-20211126T095740Z-001.zip...\n",
            "| [1 files][  2.0 GiB/  2.0 GiB]   79.9 MiB/s                                   \n",
            "Operation completed over 1 objects/2.0 GiB.                                      \n",
            "Copying gs://fruitpunch-ai-tleyden/Labeled data-20211126T095740Z-002.zip...\n",
            "/ [1 files][809.6 MiB/809.6 MiB]   83.7 MiB/s                                   \n",
            "Operation completed over 1 objects/809.6 MiB.                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"labeled_data\"):\n",
        "    !unzip -q \"Labeled data-20211126T095740Z-001.zip\"\n",
        "    !unzip -q \"Labeled data-20211126T095740Z-002.zip\""
      ],
      "metadata": {
        "id": "4QT3o_GrsTJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Re-arrange directories to match expected structure"
      ],
      "metadata": {
        "id": "pfZpqkXBvnDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"labeled_data\"):\n",
        "    os.makedirs(\"labeled_data\")\n",
        "    !mv \"Labeled data\" labeled_data\n",
        "if not os.path.exists(\"labeled_data/images/test\"):\n",
        "    !mkdir labeled_data/images/test \n",
        "    !mv labeled_data/images/*.PNG labeled_data/images/test "
      ],
      "metadata": {
        "id": "rJa_ntnutA2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47817f48-d5c9-4022-e342-ea184339acf8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already have labeled_data dir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set some global variables"
      ],
      "metadata": {
        "id": "1h5iqPpTv1_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/labeled_data/'\n",
        "\n",
        "\n",
        "use_single_batch = True\n",
        "if use_single_batch:\n",
        "    # Smaller subset of dataset for faster iteration\n",
        "    LABELS_PATH = DATA_PATH + 'annotations_single_batch/'\n",
        "    IMAGES_PATH = DATA_PATH + 'images_single_batch/'\n",
        "else:\n",
        "    LABELS_PATH = DATA_PATH + 'annotations/'\n",
        "    IMAGES_PATH = DATA_PATH + 'images/'\n",
        "\n",
        "# Get paths to IMAGE directories\n",
        "TRAIN_IMAGES_PATH = IMAGES_PATH + 'train/'\n",
        "TEST_IMAGES_PATH = IMAGES_PATH + 'test/'\n",
        "VAL_IMAGES_PATH = IMAGES_PATH + 'val/'\n",
        "\n",
        "TRAIN_LABELS = LABELS_PATH + 'instances_train.json'\n",
        "TEST_LABELS = LABELS_PATH + 'instances_test_dataset.json'\n",
        "VAL_LABELS = LABELS_PATH + 'instances_val.json'\n",
        "\n"
      ],
      "metadata": {
        "id": "YZKCCXxgvZFN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create single batch annotations\n",
        "\n",
        "Create a smaller dataset that can be used for faster iteration"
      ],
      "metadata": {
        "id": "QFinEDQXWKn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_single_batch_annotations(num_instances_to_collect):\n",
        "    \"\"\"\n",
        "    Create a copy of annotations/instances_train.json, instances_test_dataset.json and instances_val.json\n",
        "    in the annotations_single_batch directory with a smaller subset of annotations.\n",
        "    \"\"\"\n",
        "    source_annotations = [\"instances_train.json\", \"instances_test_dataset.json\", \"instances_val.json\"]\n",
        "    for source_annotation in source_annotations:\n",
        "        subset_json = {}\n",
        "        with open(os.path.join(DATA_PATH, \"annotations\", source_annotation), \"r\") as f:\n",
        "            instances_json = json.loads(f.read())\n",
        "        subset_json[\"licenses\"] = instances_json[\"licenses\"]\n",
        "        subset_json[\"info\"] = instances_json[\"info\"]\n",
        "        subset_json[\"categories\"] = instances_json[\"categories\"]\n",
        "        subset_images = []\n",
        "        subset_annotations = []\n",
        "        collected_image_ids = []\n",
        "        \n",
        "        for annotation_json in instances_json[\"annotations\"]:\n",
        "            if len(subset_annotations) >= num_instances_to_collect:\n",
        "                # We have collected enough\n",
        "                break\n",
        "            subset_annotations.append(annotation_json)\n",
        "            collected_image_ids.append(annotation_json[\"image_id\"])\n",
        "            \n",
        "        for image_json in instances_json[\"images\"]:\n",
        "            if image_json[\"id\"] not in collected_image_ids:\n",
        "                continue\n",
        "            subset_images.append(image_json)\n",
        "\n",
        "            # Copy image to target image dir\n",
        "            if \"test\" in source_annotation:\n",
        "                target_img_dir = \"test\"\n",
        "            elif \"train\" in source_annotation:\n",
        "                target_img_dir = \"train\"\n",
        "            elif \"val\" in source_annotation:\n",
        "                target_img_dir = \"val\"\n",
        "\n",
        "            file_name = image_json[\"file_name\"]\n",
        "            source_img = os.path.join(DATA_PATH, \"images\", target_img_dir, file_name)\n",
        "            target_img = os.path.join(DATA_PATH, \"images_single_batch\", target_img_dir, file_name)\n",
        "            if not os.path.exists(target_img):\n",
        "                os.link(source_img, target_img)\n",
        "\n",
        "\n",
        "        print(f\"For {source_annotation} collected {len(subset_annotations)} instances\")\n",
        "        subset_json[\"images\"] = subset_images\n",
        "        subset_json[\"annotations\"] = subset_annotations\n",
        "\n",
        "        # Write json to target dir\n",
        "        source_annotation_full_path = os.path.join(DATA_PATH, \"annotations_single_batch\", source_annotation)\n",
        "        with open(source_annotation_full_path, \"w\") as f:\n",
        "            json.dump(subset_json, f)\n",
        "        print(f\"Wrote {source_annotation_full_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "44MZIXAAWRlu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if use_single_batch:\n",
        "    if not os.path.exists(os.path.join(DATA_PATH, \"annotations_single_batch\")):\n",
        "        os.makedirs(os.path.join(DATA_PATH, \"annotations_single_batch\"))\n",
        "    if not os.path.exists(os.path.join(DATA_PATH, \"images_single_batch\")):\n",
        "        os.makedirs(os.path.join(DATA_PATH, \"images_single_batch\"))\n",
        "        os.makedirs(os.path.join(DATA_PATH, \"images_single_batch\", \"train\"))\n",
        "        os.makedirs(os.path.join(DATA_PATH, \"images_single_batch\", \"test\"))\n",
        "        os.makedirs(os.path.join(DATA_PATH, \"images_single_batch\", \"val\"))\n",
        "\n",
        "create_single_batch_annotations(64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msxKl_wvIxcf",
        "outputId": "24176dfa-dbfe-413a-9f47-9df3d93fe91b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For instances_train.json collected 64 instances\n",
            "Wrote /content/labeled_data/annotations_single_batch/instances_train.json\n",
            "For instances_test_dataset.json collected 64 instances\n",
            "Wrote /content/labeled_data/annotations_single_batch/instances_test_dataset.json\n",
            "For instances_val.json collected 64 instances\n",
            "Wrote /content/labeled_data/annotations_single_batch/instances_val.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert annotations from coco -> yolo format"
      ],
      "metadata": {
        "id": "IRb7NnkpGzY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/JSON2YOLO.git  # clone repo\n",
        "%pip install -qr JSON2YOLO/requirements.txt # install dependencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1Psxob0G41J",
        "outputId": "83a12d43-1fd9-4dc6-c4c2-f95c39ff2289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'JSON2YOLO'...\n",
            "remote: Enumerating objects: 277, done.\u001b[K\n",
            "remote: Counting objects: 100% (113/113), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 277 (delta 102), reused 84 (delta 82), pack-reused 164\u001b[K\n",
            "Receiving objects: 100% (277/277), 74.65 KiB | 1.96 MiB/s, done.\n",
            "Resolving deltas: 100% (177/177), done.\n",
            "/content/JSON2YOLO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from general_json2yolo import convert_coco_json\n",
        "\n",
        "convert_coco_json('/content/labeled_data/annotations_single_batch')\n"
      ],
      "metadata": {
        "id": "BJBH8kLjG9-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dafc870-7ea0-4db3-bb56-98e8665a9774"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Annotations /content/labeled_data/annotations_single_batch/instances_test_dataset.json: 100%|██████████| 12/12 [00:00<00:00, 2732.74it/s]\n",
            "Annotations /content/labeled_data/annotations_single_batch/instances_train.json: 100%|██████████| 64/64 [00:00<00:00, 8125.79it/s]\n",
            "Annotations /content/labeled_data/annotations_single_batch/instances_val.json: 100%|██████████| 64/64 [00:00<00:00, 7484.61it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy images to yolo dir"
      ],
      "metadata": {
        "id": "Y1DWJ-BPJh78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if use_single_batch:\n",
        "    imgs_source_dir = os.path.join(\"labeled_data\", \"images_single_batch\")\n",
        "else:\n",
        "    imgs_source_dir = os.path.join(\"labeled_data\", \"images\")\n",
        "\n",
        "imgs_train = os.path.join(imgs_source_dir, \"train\")\n",
        "imgs_test = os.path.join(imgs_source_dir, \"test\")\n",
        "imgs_val = os.path.join(imgs_source_dir, \"val\")\n",
        "\n",
        "imgs_target_dir = os.path.join(\"new_dir\", \"images\")\n",
        "imgs_target_train =  os.path.join(imgs_target_dir, \"train\")\n",
        "imgs_target_test =  os.path.join(imgs_target_dir, \"test\")\n",
        "imgs_target_val =  os.path.join(imgs_target_dir, \"val\")\n",
        "\n",
        "if os.path.exists(imgs_target_train):\n",
        "    shutil.rmtree(imgs_target_train)\n",
        "if os.path.exists(imgs_target_test):\n",
        "    shutil.rmtree(imgs_target_test)\n",
        "if os.path.exists(imgs_target_val):\n",
        "    shutil.rmtree(imgs_target_val)\n",
        "\n",
        "shutil.copytree(imgs_train, imgs_target_train)\n",
        "shutil.copytree(imgs_test, imgs_target_test)\n",
        "shutil.copytree(imgs_val, imgs_target_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CBBELtKZI97_",
        "outputId": "5be70b5f-7ac4-44bc-e64b-d251021bb0b4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'new_dir/images/val'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N3viUA5hK3DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create yolo data yaml file"
      ],
      "metadata": {
        "id": "LRmq8YRiMHJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_data_yaml = {\n",
        "    \"nc\": 1\n",
        "}"
      ],
      "metadata": {
        "id": "I3JkAPXdMIwY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}